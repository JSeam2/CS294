<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
	"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">

<head>
<title>wk1.html</title>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8"/>
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</head>

<body>

<h1>Week 1 Notes</h1>

<h2>Unsupervised Learning In a Nutshell</h2>

<ul>
<li><p>We want to learn from <strong>unlabelled data*</strong></p>

<ul>
<li><strong>Generative Models*</strong>: recreate raw data distribution</li>
<li><strong>Self-supervised learning</strong>: "Puzzle" tasks that require semantic understanding</li>
</ul></li>
<li><p>Cake analogy</p>

<ul>
<li><p><strong>Reinforcement Learning is the "Cherry"</strong>: Bot gets scalar reward once in a
while.</p>

<p>We get few bits info for some samples</p></li>
<li><p><strong>Supervised Learning is the "Icing"</strong>: Predicts human supplied data</p>

<p>We get 10-10,000 bits of info per sample</p></li>
<li><p><strong>Unsupervised/Predictive Learning is the "Cake"</strong>: Predicts any parts of
input per observed part. Prediction of future frames.</p>

<p>We get millions bits of info per sample</p></li>
</ul></li>
<li><p>Intelligence is about <strong>compression</strong> and <strong>pattern finding</strong></p>

<ul>
<li><p>Finding all patterns = short description of raw data (low Kolgorov
Complexity)</p></li>
<li><p>Shortest code length = optimal inference (Solomonoff Induction)</p></li>
<li><p>Extensible to optimal decision making agents (AIXI)</p></li>
</ul></li>
<li><p>Applications of Deep Unsupervised Learning</p>

<ul>
<li>Generation of novel data</li>
<li>Compression</li>
<li>Improve downstream tasks</li>
<li>Flexible building blocks</li>
</ul></li>
</ul>

</body>
</html>
